<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.11" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://caharper.github.io/publications/amc_deep_neural_nets.html"><meta property="og:site_name" content="Clayton Harper"><meta property="og:title" content="AMC with Deep Neural Networks"><meta property="og:description" content="TL;DR In my recent journal publication, Automatic Modulation Classification with Deep Neural Networks, we achieve state-of-the-art performance on the large-scale RadioML 2018.01..."><meta property="og:type" content="article"><meta property="og:image" content="https://caharper.github.io/"><meta property="og:locale" content="en-US"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image:alt" content="AMC with Deep Neural Networks"><meta property="article:author" content="Clayton Harper"><meta property="article:tag" content="Lead Author"><meta property="article:tag" content="MDPI"><meta property="article:tag" content="Electronics"><meta property="article:tag" content="Time Series"><meta property="article:tag" content="Modulation Classification"><meta property="article:tag" content="Journal"><meta property="article:published_time" content="2024-02-20T00:00:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"AMC with Deep Neural Networks","image":["https://caharper.github.io/"],"datePublished":"2024-02-20T00:00:00.000Z","dateModified":null,"author":[{"@type":"Person","name":"Clayton Harper","url":"https://caharper.github.io/"}]}</script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&display=swap"><title>AMC with Deep Neural Networks | Clayton Harper</title><meta name="description" content="TL;DR In my recent journal publication, Automatic Modulation Classification with Deep Neural Networks, we achieve state-of-the-art performance on the large-scale RadioML 2018.01...">
    <link rel="preload" href="/assets/style-ByeKlc0x.css" as="style"><link rel="stylesheet" href="/assets/style-ByeKlc0x.css">
    <link rel="modulepreload" href="/assets/app-Dw2r7XDh.js"><link rel="modulepreload" href="/assets/amc_deep_neural_nets.html-BGPfbiqw.js"><link rel="modulepreload" href="/assets/amc_deep_neural_nets.html-D_5Ys6ac.js">
    <link rel="prefetch" href="/assets/index.html-BiKQbtAz.js" as="script"><link rel="prefetch" href="/assets/index.html-DRKmPfsf.js" as="script"><link rel="prefetch" href="/assets/index.html-DNi6NInB.js" as="script"><link rel="prefetch" href="/assets/index.html-DTcxWAJ8.js" as="script"><link rel="prefetch" href="/assets/cmos_spectroscopy.html-DRmua3lU.js" as="script"><link rel="prefetch" href="/assets/dct_resizing.html-B2rfgoi5.js" as="script"><link rel="prefetch" href="/assets/smart_tfrecord_writer.html-D8HgkfOh.js" as="script"><link rel="prefetch" href="/assets/spectral_convolution.html-Bqu9cpa4.js" as="script"><link rel="prefetch" href="/assets/index.html-CqAFhW5x.js" as="script"><link rel="prefetch" href="/assets/learnable_moments.html-DMS_412A.js" as="script"><link rel="prefetch" href="/assets/snr_boosted_amc.html-BhBUrmW1.js" as="script"><link rel="prefetch" href="/assets/synthetic_data_trackformer.html-BP56gGGs.js" as="script"><link rel="prefetch" href="/assets/index.html-Dog0wex8.js" as="script"><link rel="prefetch" href="/assets/dct_basics.html-CjnIYg37.js" as="script"><link rel="prefetch" href="/assets/index.html-BeFuYRHw.js" as="script"><link rel="prefetch" href="/assets/endpoint_layers.html-4bCBeaw1.js" as="script"><link rel="prefetch" href="/assets/gradient_checkpointing.html-B10NFges.js" as="script"><link rel="prefetch" href="/assets/understanding_receptive_field.html-DLBCabFN.js" as="script"><link rel="prefetch" href="/assets/404.html-C6OQh4RT.js" as="script"><link rel="prefetch" href="/assets/index.html-CutByM1w.js" as="script"><link rel="prefetch" href="/assets/index.html-BE5FuOzL.js" as="script"><link rel="prefetch" href="/assets/index.html-ioLwqewY.js" as="script"><link rel="prefetch" href="/assets/index.html-C1IVGOen.js" as="script"><link rel="prefetch" href="/assets/cmos_spectroscopy.html-o_zhZdqv.js" as="script"><link rel="prefetch" href="/assets/dct_resizing.html-D30ABvvL.js" as="script"><link rel="prefetch" href="/assets/smart_tfrecord_writer.html-Dh1AGEA-.js" as="script"><link rel="prefetch" href="/assets/spectral_convolution.html-C1M8C_6H.js" as="script"><link rel="prefetch" href="/assets/index.html-B_1MIEPT.js" as="script"><link rel="prefetch" href="/assets/learnable_moments.html-CBNkH9BC.js" as="script"><link rel="prefetch" href="/assets/snr_boosted_amc.html-CzP8-5dD.js" as="script"><link rel="prefetch" href="/assets/synthetic_data_trackformer.html-Dot4XxiD.js" as="script"><link rel="prefetch" href="/assets/index.html-C-1XMSZU.js" as="script"><link rel="prefetch" href="/assets/dct_basics.html-UZi_VcVc.js" as="script"><link rel="prefetch" href="/assets/index.html-BoLYbxI_.js" as="script"><link rel="prefetch" href="/assets/endpoint_layers.html-BH3s8lsr.js" as="script"><link rel="prefetch" href="/assets/gradient_checkpointing.html-BPrTbJtS.js" as="script"><link rel="prefetch" href="/assets/understanding_receptive_field.html-qwbW-dAQ.js" as="script"><link rel="prefetch" href="/assets/404.html-KuYC986w.js" as="script"><link rel="prefetch" href="/assets/browser-D6eOinvE.js" as="script"><link rel="prefetch" href="/assets/auto-C0MMSKEI.js" as="script"><link rel="prefetch" href="/assets/index-uOBkQLRT.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-9nNZbZvi.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-BG2Xu2Hd.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-B2Y_eiOr.js" as="script"><link rel="prefetch" href="/assets/math.esm-BZ1CfUwa.js" as="script"><link rel="prefetch" href="/assets/search.esm-DuBqnxcF.js" as="script"><link rel="prefetch" href="/assets/notes.esm-Dp2Bpauq.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-Ctj_eavO.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-SzV8tJDW.js" as="script"><link rel="prefetch" href="/assets/SearchResult-BLsZpJNB.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/"><img class="vp-nav-logo" src="/assets/icon/house-solid.svg" alt><!----><span class="vp-site-name hide-in-pad">Clayton Harper</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="Projects" class="vp-link nav-link nav-link" href="/projects/"><span class="font-icon icon fa-fw fa-sm fas fa-laptop-code" style=""></span>Projects<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Blog" class="vp-link nav-link nav-link" href="/blog/"><span class="font-icon icon fa-fw fa-sm fas fa-pen-nib" style=""></span>Blog<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Publications" class="vp-link nav-link active nav-link active" href="/publications/"><span class="font-icon icon fa-fw fa-sm fas fa-file-alt" style=""></span>Publications<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="About" class="vp-link nav-link nav-link" href="/about/"><span class="font-icon icon fa-fw fa-sm fas fa-user" style=""></span>About<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/caharper" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-heading clickable"><span class="font-icon icon fa-fw fa-sm fas fa-laptop-code" style=""></span><a aria-label="Projects" class="vp-link nav-link vp-sidebar-title nav-link vp-sidebar-title" href="/projects/"><!---->Projects<!----></a><!----></p><ul class="vp-sidebar-links"><li><!--[--><a aria-label="CMOS-Based Rotational Spectroscopy" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/projects/cmos_spectroscopy.html"><!---->CMOS-Based Rotational Spectroscopy<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="DCT Resizing in Neural Networks" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/projects/dct_resizing.html"><!---->DCT Resizing in Neural Networks<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="smart-tfrecord-writer" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/projects/smart_tfrecord_writer.html"><!---->smart-tfrecord-writer<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Spectral Convolution in Neural Networks" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/projects/spectral_convolution.html"><!---->Spectral Convolution in Neural Networks<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-heading clickable"><span class="font-icon icon fa-fw fa-sm fas fa-pen-nib" style=""></span><a aria-label="Blog" class="vp-link nav-link vp-sidebar-title nav-link vp-sidebar-title" href="/blog/"><!---->Blog<!----></a><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">Frequency Analysis</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">Understanding ML</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-heading clickable active"><span class="font-icon icon fa-fw fa-sm fas fa-file-alt" style=""></span><a aria-label="Publications" class="vp-link nav-link active vp-sidebar-title nav-link active vp-sidebar-title" href="/publications/"><!---->Publications<!----></a><!----></p><ul class="vp-sidebar-links"><li><!--[--><a aria-label="AMC with Deep Neural Networks" class="vp-link nav-link active vp-sidebar-link vp-sidebar-page active nav-link active vp-sidebar-link vp-sidebar-page active" href="/publications/amc_deep_neural_nets.html"><!---->AMC with Deep Neural Networks<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="Publication Information" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/publications/amc_deep_neural_nets.html#publication-information"><!---->Publication Information<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Paper Contributions" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/publications/amc_deep_neural_nets.html#paper-contributions"><!---->Paper Contributions<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Paper Purpose" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/publications/amc_deep_neural_nets.html#paper-purpose"><!---->Paper Purpose<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Methodology" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/publications/amc_deep_neural_nets.html#methodology"><!---->Methodology<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Results" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/publications/amc_deep_neural_nets.html#results"><!---->Results<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Takeaways" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/publications/amc_deep_neural_nets.html#takeaways"><!---->Takeaways<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="References" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/publications/amc_deep_neural_nets.html#references"><!---->References<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul><!--]--></li><li><!--[--><a aria-label="Impacts of Synthetically Generated Data on Trackformer-based Multi-Object Tracking" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/publications/synthetic_data_trackformer.html"><!---->Impacts of Synthetically Generated Data on Trackformer-based Multi-Object Tracking<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Learnable Statistical Moments Pooling" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/publications/learnable_moments.html"><!---->Learnable Statistical Moments Pooling<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="SNR-Boosted AMC" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/publications/snr_boosted_amc.html"><!---->SNR-Boosted AMC<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->AMC with Deep Neural Networks</h1><div class="page-info"><span class="page-author-info" aria-label="AuthorðŸ–Š" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://caharper.github.io/" target="_blank" rel="noopener noreferrer">Clayton Harper</a></span><span property="author" content="Clayton Harper"></span></span><!----><span class="page-date-info" aria-label="Writing DateðŸ“…" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-02-20T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading TimeâŒ›" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 5 min</span><meta property="timeRequired" content="PT5M"></span><span class="page-category-info" aria-label="CategoryðŸŒˆ" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category4" role>Publication</span><span class="page-category-item category1" role>Research</span><!--]--><meta property="articleSection" content="Publication,Research"></span><span class="page-tag-info" aria-label="TagðŸ·" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag5" role>Lead Author</span><span class="page-tag-item tag3" role>MDPI</span><span class="page-tag-item tag6" role>Electronics</span><span class="page-tag-item tag3" role>Time Series</span><span class="page-tag-item tag4" role>Modulation Classification</span><span class="page-tag-item tag3" role>Journal</span><!--]--><meta property="keywords" content="Lead Author,MDPI,Electronics,Time Series,Modulation Classification,Journal"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#publication-information">Publication Information</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#paper-contributions">Paper Contributions</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#paper-purpose">Paper Purpose</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#methodology">Methodology</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#results">Results</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#takeaways">Takeaways</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#references">References</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><div class="vp-share-buttons" style=""><!--[--><button type="button" class="vp-share-button" aria-label="email" data-balloon-pos="up"><div class="vp-share-icon colorful" style="background:#1384FF;"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024"><path d="M152 177h720c49 0 89 37 90 83L512 494 63 260c0-46 40-83 89-83M62 349v414c0 46 41 84 90 84h720c49 0 90-38 90-84V349L523 572a24 24 0 0 1-22 0z"/></svg></div></button><!----><!--]--><!--[--><button type="button" class="vp-share-button" aria-label="facebook" data-balloon-pos="up"><div class="vp-share-icon colorful" style="background:#3c599b;"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024"><path d="M295 360h93v-91c0-40 1-101 30-139 30-41 72-68 144-68 118 0 168 17 168 17l-24 138s-39-12-75-12-69 13-69 50v105h149l-10 134H562v468H388V494h-93z"/></svg></div></button><!----><!--]--><!--[--><button type="button" class="vp-share-button" aria-label="reddit" data-balloon-pos="up"><div class="vp-share-icon colorful" style="background:#ff4501;"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024"><path d="M678 779c9 9 9 18 0 27-34 37-90 55-166 55s-132-18-166-55c-9-9-9-18 0-27a17 17 0 0 1 12-6c5 0 9 2 13 6 26 29 74 43 141 43s114-14 141-43a17 17 0 0 1 13-6c5 0 9 2 12 6M400 562a82 82 0 0 1 0 112 70 70 0 0 1-53 23c-20 0-38-8-53-23a78 78 0 0 1-22-56c0-22 7-41 22-56a71 71 0 0 1 106 0m352 56c0 22-7 41-22 56a71 71 0 0 1-53 23c-21 0-38-8-53-23a78 78 0 0 1-22-56c0-22 8-40 22-56 15-16 32-23 53-23 20 0 38 7 53 23 15 15 22 34 22 56m210-106c0-29-10-54-29-74a94 94 0 0 0-71-31c-28 0-52 10-72 31-73-53-160-81-260-85l52-250 168 40c0 21 7 40 21 55 15 16 32 23 53 23s38-7 53-23 22-34 22-56-7-41-22-57a71 71 0 0 0-53-23c-30 0-52 15-67 44L572 63c-10-3-17 2-21 14l-57 276c-101 5-187 33-259 86a94 94 0 0 0-73-32c-28 0-51 10-71 31a105 105 0 0 0-29 74 108 108 0 0 0 57 96 241 241 0 0 0-5 49c0 84 39 156 117 216 78 59 172 89 282 89s205-30 283-89c78-60 117-132 117-216 0-19-2-35-6-50a108 108 0 0 0 55-95"/></svg></div></button><!----><!--]--><!--[--><button type="button" class="vp-share-button" aria-label="twitter" data-balloon-pos="up"><div class="vp-share-icon colorful" style="background:#000;"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024"><path d="m587 451 291-339h-69L555 407 354 112H120l305 446-305 354h68l268-310 213 310h235zM214 163h107l488 699H702z"/></svg></div></button><!----><!--]--></div><div class="hint-container info"><p class="hint-container-title">TL;DR</p><p>In my recent journal publication, <em>Automatic Modulation Classification with Deep Neural Networks</em>, we achieve state-of-the-art performance on the large-scale RadioML 2018.01A dataset with a peak accuracy of 98.9% and an overall accuracy of 63.7%. Automatic modulation classification (AMC) is critical for modern communication systems, and poses a significant time series classification challenge. We meticulously analyze and compare various convolutional deep learning architectures, finding the most instrumental network design components for AMC.</p></div><h2 id="publication-information" tabindex="-1"><a class="header-anchor" href="#publication-information" aria-hidden="true">#</a> Publication Information</h2><p><code>Title</code>: Automatic Modulation Classification with Deep Neural Networks</p><p><code>Authors</code>: Clayton Harper, Mitchell A. Thornton, Eric C. Larson</p><p><code>Venue</code>: MPDI Electronics Journal</p><p><code>Publication Date</code>: September 2023</p><p><code>Status</code>: <span class="vp-badge tip" style="vertical-align:middle;">Published</span></p><div><div class="vp-site-info" data-name="Paper GitHub"><a class="vp-site-info-navigator" title="Paper GitHub" href="https://github.com/caharper/Automatic-Modulation-Classification-with-Deep-Neural-Networks" target="_blank"></a><div class="vp-site-info-preview" style="background:url(/assets/publications/amc_deep_neural_nets/amc_git.png) center/cover no-repeat;"></div><div class="vp-site-info-detail"><!----><div class="vp-site-info-name">Paper GitHub</div><div class="vp-site-info-desc"></div></div><div class="vp-site-info-source-wrapper"><a class="vp-site-info-source" href="https://github.com/caharper/Automatic-Modulation-Classification-with-Deep-Neural-Networks" aria-label="Source" data-balloon-pos="left" title="Source" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div></div><div class="vp-site-info" data-name="Paper Link"><a class="vp-site-info-navigator" title="Paper Link" href="https://www.mdpi.com/2079-9292/12/18/3962" target="_blank"></a><div class="vp-site-info-preview" style="background:url(/assets/publications/amc_deep_neural_nets/amc_electronics.png) center/cover no-repeat;"></div><div class="vp-site-info-detail"><!----><div class="vp-site-info-name">Paper Link</div><div class="vp-site-info-desc">MDPI Electronics Paper</div></div><!----></div></div><p><code>BibTeX Citation</code>:</p><div class="language-bibtex line-numbers-mode" data-ext="bibtex"><pre class="language-bibtex"><code>@article{harper2023automatic,
  title={Automatic Modulation Classification with Deep Neural Networks},
  author={Harper, Clayton A and Thornton, Mitchell A and Larson, Eric C},
  journal={Electronics},
  volume={12},
  number={18},
  pages={3962},
  year={2023},
  publisher={MDPI}
}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><details class="hint-container details"><summary>Paper PDF</summary><div class="pdf-viewer-wrapper" style="width:100%;height:auto;"></div></details><h2 id="paper-contributions" tabindex="-1"><a class="header-anchor" href="#paper-contributions" aria-hidden="true">#</a> Paper Contributions</h2><ol><li>We achieve state-of-the-art performance on the RadioML 2018.01A dataset with a peak accuracy of 98.9% and an overall accuracy of 63.7%.</li><li>Thorough investigation on multiple design elements (e.g., self-attention, X-Vectors, dilated convolutions, and Squeeze-and-Excitation blocks, and nonlinear activatin placement) and their impacts on AMC performance.</li><li>Increased receptive field was found to be the most influential factor in improving AMC performance.</li></ol><h2 id="paper-purpose" tabindex="-1"><a class="header-anchor" href="#paper-purpose" aria-hidden="true">#</a> Paper Purpose</h2><p>Although I have published other papers on automatic modulation classification (AMC)<sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup><sup class="footnote-ref"><a href="#footnote2">[2]</a><a class="footnote-anchor" id="footnote-ref2"></a></sup>, they were shorter conference publications and served as stepping stones to this work. Additionally, many AMC papers focus heavily on single design elements to improve performance (including my previous work). However, there seemed to be a lack of comprehensive analysis on the impacts of different design elements on AMC performance. This is crucial for understanding which factors are most important for AMC design and for guiding future research in this area. Ultimately, the purpose of this work was centered around an exhaustive analysis of various deep learning architectures using the RadioML 2018.01A dataset to accomplish our goal of finding the most influential network design components for AMC.</p><h2 id="methodology" tabindex="-1"><a class="header-anchor" href="#methodology" aria-hidden="true">#</a> Methodology</h2><p>Our template architecture can be seen below where each colored block represents an adjustable component in our ablation study.</p><div class="hint-container note"><p class="hint-container-title">&quot;Ablation&quot; Study</p><p>An ablation study in this context is a method of systematically removing components from a system to understand their individual impacts on the system&#39;s performance. In other words, we try every combination of components and compare their results to see which components are most influential.</p></div><figure><img src="/assets/base_arch-Ds_m-09R.png" alt="Template architecture to explore." tabindex="0" loading="lazy"><figcaption>Template architecture to explore.</figcaption></figure><p>Squeeze-and-Excitation (SE) blocks<sup class="footnote-ref"><a href="#footnote3">[3]</a><a class="footnote-anchor" id="footnote-ref3"></a></sup> aim to increase the receptive field of convolutional layers by providing global context through statistical aggregations followed by a recalibration of the feature maps. To make this post more succinct, I will not go into the exact details of our SE blocks; however, the main takeaway is that the mean of each channel is taken, followed by a fully connected layer, and then a sigmoid activation. This is then multiplied with the original feature map to recalibrate the activations. We also explore the impacts of X-Vector (mean and variance) embeddings, dilated convolutions, and nonlinear activation placement. We then compare the performance of each architecture combination on the RadioML 2018.01A dataset.</p><h2 id="results" tabindex="-1"><a class="header-anchor" href="#results" aria-hidden="true">#</a> Results</h2><table><caption>Ablation study performance overview.</caption><thead><tr><th>Model Name</th><th>Notes</th><th>SENet</th><th>Dilated Convolutions</th><th>Final Activation</th><th>Attention</th><th># Params</th><th>Avg. Accuracy</th><th>Max Accuracy</th></tr></thead><tbody><tr><td>0000</td><td></td><td>---</td><td>---</td><td>---</td><td>---</td><td>174,000</td><td>62.9%</td><td>98.6%</td></tr><tr><td>0001</td><td></td><td>---</td><td>---</td><td>---</td><td>âœ”</td><td>221,088</td><td>62.3%</td><td>97.6%</td></tr><tr><td>0010</td><td></td><td>---</td><td>---</td><td>âœ”</td><td>---</td><td>174,000</td><td>62.8%</td><td>98.6%</td></tr><tr><td>0011</td><td></td><td>---</td><td>---</td><td>âœ”</td><td>âœ”</td><td>221,088</td><td>62.3%</td><td>97.5%</td></tr><tr><td>0100</td><td></td><td>---</td><td>âœ”</td><td>---</td><td>---</td><td>174,000</td><td>63.2%</td><td>98.9%</td></tr><tr><td>0101</td><td></td><td>---</td><td>âœ”</td><td>---</td><td>âœ”</td><td>221,088</td><td>63.1%</td><td>97.9%</td></tr><tr><td>0110</td><td></td><td>---</td><td>âœ”</td><td>âœ”</td><td>---</td><td>174,000</td><td>63.2%</td><td>98.9%</td></tr><tr><td>0111</td><td></td><td>---</td><td>âœ”</td><td>âœ”</td><td>âœ”</td><td>221,088</td><td>63.0%</td><td>98.0%</td></tr><tr><td>1000</td><td></td><td>âœ”</td><td>---</td><td>---</td><td>---</td><td>202,880</td><td>62.9%</td><td>98.5%</td></tr><tr><td>1001</td><td></td><td>âœ”</td><td>---</td><td>---</td><td>âœ”</td><td>249,968</td><td>62.6%</td><td>98.2%</td></tr><tr><td>1010</td><td></td><td>âœ”</td><td>---</td><td>âœ”</td><td>---</td><td>202,880</td><td>62.6%</td><td>98.3%</td></tr><tr><td>1011</td><td></td><td>âœ”</td><td>---</td><td>âœ”</td><td>âœ”</td><td>249,968</td><td>62.8%</td><td>98.1%</td></tr><tr><td>1100</td><td></td><td>âœ”</td><td>âœ”</td><td>---</td><td>---</td><td>202,880</td><td>62.8%</td><td>98.2%</td></tr><tr><td>1101</td><td></td><td>âœ”</td><td>âœ”</td><td>---</td><td>âœ”</td><td>249,968</td><td>63.0%</td><td>97.7%</td></tr><tr><td>1110</td><td>Overall best performing model</td><td>âœ”</td><td>âœ”</td><td>âœ”</td><td>---</td><td>202,880</td><td>63.7%</td><td>98.9%</td></tr><tr><td>1111</td><td></td><td>âœ”</td><td>âœ”</td><td>âœ”</td><td>âœ”</td><td>249,968</td><td>63.0%</td><td>97.8%</td></tr></tbody></table><p>Ultimately, we found that the combination of dilated convolutions, SE blocks, and a final activation layer provided the best performance. This model achieved a peak accuracy of 98.9% and an overall accuracy of 63.7%. Each of these factors increase receptive field, which is likely why they improved AMC performance. Self-attention was found to degrade performance, possibly due to the increase in parameters comlicating the loss space.</p><p>Using an X-Vector (i.e., using the mean and variance of the feature maps) based architecture, our models naturally handle variable length inputs. This is crucial for AMC, as the length of input signals in the wild can vary significantly. By using the X-Vector approach, we are able to compare the performance of our models with different signal burst lengths. In return, we can better understand the limitations of our models by observing how performance degrades as the burst length deceases. To ensure the graph is not too cluttered while also providing analysis for different modulation schemes, we group the 24 modulation schemes from the RadioML 2018.01A dataset into 4 groups. This grouping can be seen below:</p><ul><li><strong>Amplitude</strong>: OOK, 4ASK, 8ASK, AM-SSB-SC, AM-SSB-WC, AM-DSB-WC, AM-DSB-SC</li><li><strong>Phase</strong>: BPSK, QPSK, 8PSK, 16PSK, 32PSK, OQPSK</li><li><strong>Amplitude and Phase</strong>: 16APSK, 32APSK, 64APSK, 128APSK, 16QAM, 32QAM, 64QAM, 128QAM, 256QAM</li><li><strong>Frequency</strong>: FM, GMSK</li></ul><p>Using our best performing model, 1110, we compare the performance of our model with different burst lengths below:</p><figure><img src="/assets/signal_burst-BJK146hq.png" alt="AMC performance under various burst lengths for model 1110." tabindex="0" loading="lazy"><figcaption>AMC performance under various burst lengths for model 1110.</figcaption></figure><p>We find that performance is resilient to changes in burst length down to about 256 <mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.489ex;" xmlns="http://www.w3.org/2000/svg" width="1.364ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 603 658" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Î¼</mi></math></mjx-assistive-mml></mjx-container>s. However, we are still able to achieve above random chance accuracy down to 16 <mjx-container class="MathJax" jax="SVG" style="position:relative;"><svg style="vertical-align:-0.489ex;" xmlns="http://www.w3.org/2000/svg" width="1.364ex" height="1.489ex" role="img" focusable="false" viewBox="0 -442 603 658" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D707" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>Î¼</mi></math></mjx-assistive-mml></mjx-container>s. This is crucial for AMC, as the length of recieved signals is not a guarantee and can vary significantly with various channel conditions.</p><h2 id="takeaways" tabindex="-1"><a class="header-anchor" href="#takeaways" aria-hidden="true">#</a> Takeaways</h2><p>Factors that increase the receptive field of convolutional layers (e.g., kernel size, dilation rate, SE blocks) are the most influential in improving AMC performance. This is likely due to the fact that AMC is a time series classification task, and the receptive field of the network determines the temporal extent of the features that the network can learn. This work provides a comprehensive analysis of the impacts of various deep learning architectures on AMC performance, and provides guidance for future research in this area.</p><h2 id="references" tabindex="-1"><a class="header-anchor" href="#references" aria-hidden="true">#</a> References</h2><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="footnote1" class="footnote-item"><p><a href="https://ieeexplore.ieee.org/abstract/document/9443358" target="_blank" rel="noopener noreferrer">Enhanced Automatic Modulation Classification using Deep Convolutional Latent Space Pooling<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> <a href="#footnote-ref1" class="footnote-backref">â†©ï¸Ž</a></p></li><li id="footnote2" class="footnote-item"><p><a href="https://ieeexplore.ieee.org/abstract/document/9723370" target="_blank" rel="noopener noreferrer">SNR-Boosted Automatic Modulation Classification<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><div class="hint-container important"><p class="hint-container-title">See Also</p><p>I have also written a short article on this site, <a href="/publications/snr_boosted_amc">SNR-Boosted Automatic Modulation Classification</a> that provides a 50,000 foot view of this work.</p></div><a href="#footnote-ref2" class="footnote-backref">â†©ï¸Ž</a></li><li id="footnote3" class="footnote-item"><p><a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html" target="_blank" rel="noopener noreferrer">Squeeze-and-excitation networks<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> <a href="#footnote-ref3" class="footnote-backref">â†©ï¸Ž</a></p></li></ol></section></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><!----><a aria-label="Impacts of Synthetically Generated Data on Trackformer-based Multi-Object Tracking" class="vp-link nav-link next nav-link next" href="/publications/synthetic_data_trackformer.html"><div class="hint">Next<span class="arrow end"></span></div><div class="link">Impacts of Synthetically Generated Data on Trackformer-based Multi-Object Tracking<!----></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><footer class="vp-footer-wrapper"><!----><div class="vp-copyright">Copyright Â© 2024 Clayton Harper </div></footer></div><!--]--><!--]--><!----><!----><!--]--></div>
    <script type="module" src="/assets/app-Dw2r7XDh.js" defer></script>
  </body>
</html>
