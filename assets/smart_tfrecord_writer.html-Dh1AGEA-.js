import{_ as p,r as o,o as c,c as l,b as a,f as s,d as n,e as t}from"./app-Dw2r7XDh.js";const r="/assets/smart_writer-BwmtuCp5.png",u={},d={class:"hint-container info"},m=s("p",{class:"hint-container-title"},"TL;DR",-1),k={href:"https://github.com/caharper/smart-tfrecord-writer",target:"_blank",rel:"noopener noreferrer"},h=s("code",null,"smart-tfrecord-writer",-1),v=t(`<p>Install now:</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>pip <span class="token function">install</span> smart-tfrecord-writer
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,2),b={href:"https://github.com/caharper/smart-tfrecord-writer",target:"_blank",rel:"noopener noreferrer"},f=s("code",null,"tensorflow-datasets",-1),g=t('<p>The major benefits of the <code>smart-tfrecord-writer</code> are:</p><ul><li>You only need to write two basic functions to write your data to TFRecord files.</li><li>It is directly compatible with <code>tensorflow-datasets</code> so you can easily use it with the <code>tfds</code> package (e.g., <code>tfds.load</code>).</li><li>It provides progress bar feedback as well as memory estimates for the TFRecord files so you can monitor the progress of writing your data and know if you would run out of memory before you actually do! ðŸ˜„</li></ul><h2 id="why-you-should-care" tabindex="-1"><a class="header-anchor" href="#why-you-should-care" aria-hidden="true">#</a> Why You Should Care</h2><p>If you are not using TFRecord files to store your datasets, you may be under-utilizing your GPU. This will limit your training speeds and potentially increase your training costs if you are paying for GPU/accelerator time.</p><p>If you held back from using TFRecord files because you found the process of writing data to them to be complex and time-consuming, then <code>smart-tfrecord-writer</code> is for you! It is designed to simplify the process of writing data to TFRecord files and to provide a tool that can be used across a wide range of projects. You do <strong>not</strong> need to be a TFRecord expert to use this package.</p><div class="hint-container tip"><p class="hint-container-title">Note</p><p>TFRecord format is not just for TensorFlow users! It is a binary file format that is optimized for reading and writing large datasets. It can be used with any machine learning framework. Checkout PyTorch and JAX guides for reading TFRecord files.</p></div><h2 id="background" tabindex="-1"><a class="header-anchor" href="#background" aria-hidden="true">#</a> Background</h2><p>During my time as a PhD student, I have worked on projects across a diverse range of data types and sizes. When first learning how to use common machine learning packages (e.g., TensorFlow, PyTorch, Keras, and JAX), many tutorials and examples use small datasets that can be easily loaded into memory (hello <code>tf.data.Dataset.from_tensor_slices</code>). However, in practice, many (most) datasets are too large to fit into memory. When this is the case, many students (including myself at one point) implement the naive solution of building a data generator, whether it be a basic Python generator, a <code>tf.data</code> pipeline using many <code>tf.py_function</code>s for data loading, a <code>torch.utils.data.Dataset</code>, etc. that read data from scattered, individual files on disk to feed it into the model. For example, when working with a large image dataset such as ImageNet, individual images are often stored as separate <code>.jpg</code> files on disk. The naive solution retrieves a single image from disk, processes it, and then retrieves the next image.</p><p>While this may get things running, it is a slow and inefficient solution that can greatly reduce the speed of training and can be a major bottleneck in the machine learning workflow. So much so that it can make training a model infeasible. Even if you are using multiple workers to read data in parallel, the overhead of reading data from disk can be a major bottleneck. This is especially true when working on remote file systems or cloud storage using hard drives or network storage. The slowdown comes from seek operations, reading small amounts of data at a time, and the overhead of opening and closing files. This is where TFRecord files come to the rescue.</p><div class="hint-container note"><p class="hint-container-title">Note</p><p>Using naive solutions first became a problem for me several years ago when I was working on a speaker verification project containing close to <code>~1TB</code> of audio data. I was using a Python generator to read the audio files from disk. This was a major bottleneck in my workflow, and it was taking over a day to train a single epoch. This made me investigate how ML practitioners handle large datasets in industry, and I found that TFRecord files are a common solution.</p></div><p>TFRecord files are a binary file format that is optimized for reading and writing large datasets. They are designed to be used with TensorFlow, but they can be used with any machine learning framework. They are designed to be efficient for reading and writing large datasets, and they can be used to store any type of data, such as images, audio, video, text, and more. For these reasons, I began to convert my data to TFRecord files, and I found that it greatly improved the speed of my training workflows.</p>',11),y={href:"https://github.com/caharper/smart-tfrecord-writer",target:"_blank",rel:"noopener noreferrer"},w=s("code",null,"smart-tfrecord-writer",-1),_=t(`<p>For nearly all my projects, I utilize <code>smart-tfrecord-writer</code> to write my data to TFRecord files. I have found it to be a major time-saver and a great tool to have in my toolbox. I hope you find it useful as well!</p><h2 id="usage" tabindex="-1"><a class="header-anchor" href="#usage" aria-hidden="true">#</a> Usage</h2><p>At the core of <code>smart-tfrecord-writer</code> is the <code>Writer</code> class. The <code>Writer</code> class is designed to be easy to use and to handle the complexities of writing data to TFRecord files. When you want to convert your data to TFRecord files, you subclass <code>Writer</code> and you only need to write two basic functions: <code>Writer.features()</code> and <code>Writer.process_data()</code>, and you need to supply an iterator for the writer. Let&#39;s take a look at the iterator first and then the two functions.</p><h3 id="iterator" tabindex="-1"><a class="header-anchor" href="#iterator" aria-hidden="true">#</a> Iterator</h3><p>The iterator is a simple Python generator that yields the data that you want to write to the TFRecord files. The data can be in any format, such as a list of dictionaries, a list of tuples, a list of lists, etc. The only requirement is that the data must be in a format that can be processed by the <code>Writer.process_data()</code> function. The iterator can be as simple or as complex as you need it to be. In order to let the writer know how to save the data, you should create an object named <code>split_info</code>. This object should have the following structure:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>splits_info <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;&lt;split_name&gt;&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;info&quot;</span><span class="token punctuation">:</span> split_info
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Where <code>splits_info</code> is a list of of dictionaries. Each dictionary is a split of the dataset. The <code>name</code> key is the name of the split (e.g. train, test, validation, or anything you want), and the <code>info</code> key is the iterator.</p><div class="hint-container warning"><p class="hint-container-title">Warning</p><p>There is a small caveat to the value for the <code>name</code> key. Because tensorflow-datasets assumes a certain file naming structure, you cannot include the following characters in the <code>name</code> value: <code>-</code> or <code>.</code>. If you do, you will get an error during the TFRecord dataset creation.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>splits_info <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;data.train-1&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;info&quot;</span><span class="token punctuation">:</span> split_info
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span> <span class="token comment"># Will not work</span>

splits_info <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;data_train_1&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;info&quot;</span><span class="token punctuation">:</span> split_info
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span> <span class="token comment"># Will work</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><p>A very simple example of a <code>splits_info</code> object is shown below:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>train_iterator <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_iterator <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
splits_info <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;info&quot;</span><span class="token punctuation">:</span> train_iterator
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{</span>
        <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;info&quot;</span><span class="token punctuation">:</span> test_iterator
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container important"><p class="hint-container-title">Important</p><p>For your iterator to be compatible with <code>smart-tfrecord-writer</code>, it must be an iterable object that has a defined <code>__len__</code> method. This is because the writer needs to know the length of the iterator to provide progress bar feedback and memory estimates for the TFRecord files.</p></div><h3 id="writer-features" tabindex="-1"><a class="header-anchor" href="#writer-features" aria-hidden="true">#</a> <code>Writer.features()</code></h3>`,12),q=s("code",null,"Writer.features()",-1),x={href:"https://www.tensorflow.org/datasets",target:"_blank",rel:"noopener noreferrer"},T={href:"https://www.tensorflow.org/datasets/api_docs/python/tfds/features",target:"_blank",rel:"noopener noreferrer"},F=t(`<p>Given the specifics of your data, you will need to define the features that you want to store in the TFRecord file. A simple image classification dataset example is shown below.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow_datasets <span class="token keyword">as</span> tfds
<span class="token keyword">from</span> smart_tfrecord_writer <span class="token keyword">import</span> Writer
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">class</span> <span class="token class-name">ImageWriter</span><span class="token punctuation">(</span>Writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">features</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        features <span class="token operator">=</span> tfds<span class="token punctuation">.</span>features<span class="token punctuation">.</span>FeaturesDict<span class="token punctuation">(</span>
            <span class="token punctuation">{</span>
                <span class="token string">&quot;image&quot;</span><span class="token punctuation">:</span> tfds<span class="token punctuation">.</span>features<span class="token punctuation">.</span>Image<span class="token punctuation">(</span>
                    shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">,</span>  <span class="token comment"># Image feature expects uint8</span>
                    doc<span class="token operator">=</span><span class="token string">&quot;Image from the dataset.&quot;</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token string">&quot;label&quot;</span><span class="token punctuation">:</span> tfds<span class="token punctuation">.</span>features<span class="token punctuation">.</span>ClassLabel<span class="token punctuation">(</span>
                    names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;dog&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;cat&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">)</span>

        <span class="token keyword">return</span> features
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Generally speaking, this is the more simple of the two functions to implement. However, you need to make sure your data types align!</p><h3 id="writer-process-data" tabindex="-1"><a class="header-anchor" href="#writer-process-data" aria-hidden="true">#</a> <code>Writer.process_data()</code></h3><p>The purpose of this function is to take in a single example from the iterator and to return a dictionary of the features that you defined in <code>Writer.features()</code>. This function is where you will do any data processing that is necessary to get your data into the format that you want to store in the TFRecord file. In other words, this function is called like the following pseudocode:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>train_iterator <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
splits_info <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;info&quot;</span><span class="token punctuation">:</span> train_iterator
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

writer <span class="token operator">=</span> ImageWriter<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> split_name<span class="token punctuation">,</span> split_info <span class="token keyword">in</span> splits_info<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> example <span class="token keyword">in</span> split_info<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span> <span class="token comment"># Would print 0, 1, ..., 99</span>
        example <span class="token operator">=</span> writer<span class="token punctuation">.</span>process_data<span class="token punctuation">(</span>example<span class="token punctuation">)</span>
        <span class="token comment"># Write example to TFRecord file</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,6),I=s("code",null,"smart-tfrecord-writer",-1),W={href:"https://github.com/caharper/smart-tfrecord-writer/tree/main/examples",target:"_blank",rel:"noopener noreferrer"},R=s("code",null,"process_data",-1),j=t(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>
<span class="token keyword">class</span> <span class="token class-name">ImageWriter</span><span class="token punctuation">(</span>Writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> example<span class="token punctuation">)</span><span class="token punctuation">:</span>
        image<span class="token punctuation">,</span> label <span class="token operator">=</span> example
        <span class="token keyword">return</span> <span class="token punctuation">{</span>
            <span class="token string">&quot;image&quot;</span><span class="token punctuation">:</span> image<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">&quot;label&quot;</span><span class="token punctuation">:</span> label
        <span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="optional-methods" tabindex="-1"><a class="header-anchor" href="#optional-methods" aria-hidden="true">#</a> Optional Methods</h2><p>The most important optional method is the <code>Writer.extend_meta_data()</code> method. This method is used to extend the metadata of the dataset. The metadata is used by <code>tensorflow-datasets</code> to provide information about the dataset. This includes the following:</p><ul><li><code>description</code>: A string that is a description of the dataset.</li><li><code>homepage</code>: A URL to the homepage of the dataset.</li><li><code>supervised_keys</code>: A tuple of strings that are the keys of the supervised keys in the dataset. This only applies to supervised datasets.</li><li><code>citation</code>: A string that is the citation for the dataset.</li></ul><p>The <code>Writer.extend_meta_data()</code> method should return the <code>description</code>, <code>homepage</code>, <code>supervised_keys</code>, and <code>citation</code> of the dataset. If the dataset is supervised, the <code>supervised_keys</code> should be a tuple of strings that are the keys of the supervised keys in the dataset. If there is no citation, the <code>citation</code> should be an empty string and likewise for the <code>homepage</code> and <code>description</code>. An example of how to use this method is shown below:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">ImageWriter</span><span class="token punctuation">(</span>Writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">extend_meta_data</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        description <span class="token operator">=</span> <span class="token string">&quot;A dataset of images of cats and dogs.&quot;</span>
        homepage <span class="token operator">=</span> <span class="token string">&quot;https://www.example.com&quot;</span>
        supervised_keys <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">&quot;image&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;label&quot;</span><span class="token punctuation">)</span>
        citation <span class="token operator">=</span> <span class="token triple-quoted-string string">&quot;&quot;&quot;
        @article{example,
            title={An example article},
            author={John Doe},
            journal={Example Journal},
            year={2024},
            volume={1},
            pages={1-10}
        }
        &quot;&quot;&quot;</span>

        <span class="token keyword">return</span> description<span class="token punctuation">,</span> homepage<span class="token punctuation">,</span> supervised_keys<span class="token punctuation">,</span> citation
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="writing-records" tabindex="-1"><a class="header-anchor" href="#writing-records" aria-hidden="true">#</a> Writing Records</h2><p>Once you have defined your <code>Writer</code> class, you can write your data to TFRecord files using the <code>Writer.write_records()</code> method. The <code>Writer.write_records()</code> method takes in the <code>splits_info</code> object. The <code>Writer.write_records()</code> method will create a directory structure that is compatible with <code>tensorflow-datasets</code> and will save the TFRecord files in the appropriate location.</p><p>A great benefit of using <code>smart-tfrecord-writer</code> is that it provides progress bar feedback (check out the <code>verbose</code> parameter to <code>Writer.write_records()</code>) as well as the ability to specify the target amount of memory for each TFRecord file (shard). Generally speaking, a shard will contain several examples. This is how TFRecords have faster loading as shards are saved in contiguous blocks of memory so one seek operation can read many examples. By specifying the <code>mb_per_shard</code> parameter, you can control the approximate size (in MB) of each shard. You want this number small enough to fit into memory, but large enough to minimize the number of files you have to deal with. About 250MB is a good starting point.</p><p><code>smart-tfrecord-writer</code> will estimate the memory usage of each example to get an estimate for how many examples can fit into each shard. In many cases, dataset features are of fixed shape. For example, all the images in the dataset are of shape <code>(32, 32, 3)</code>. In this case, using <code>n_estimates_mb_per_example</code> can be set to 1 to avoid the overhead of estimating the memory usage of each example since each will be the same size (no need to estimate more). If you have variable length features, you should set this to a larger number to get a more accurate estimate of the memory usage of each example. However, the larger this number, the slower the estimation process will be.</p><p>Here is an example of how to use the <code>Writer.write_records()</code> method:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>writer<span class="token punctuation">.</span>write_records<span class="token punctuation">(</span>
    splits_info<span class="token operator">=</span>splits_info<span class="token punctuation">,</span>
    mb_per_shard<span class="token operator">=</span><span class="token number">250</span><span class="token punctuation">,</span>
    n_estimates_mb_per_example<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>When this is run, you&#39;ll see an output like the following:</p><figure><img src="`+r+'" alt="smart-tfrecord-writer example output." tabindex="0" loading="lazy"><figcaption>smart-tfrecord-writer example output.</figcaption></figure><h2 id="complete-example" tabindex="-1"><a class="header-anchor" href="#complete-example" aria-hidden="true">#</a> Complete Example</h2>',15),A=s("code",null,"smart-tfrecord-writer",-1),z={href:"https://github.com/caharper/smart-tfrecord-writer/tree/main/examples/imagenet",target:"_blank",rel:"noopener noreferrer"},D=t(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow_datasets <span class="token keyword">as</span> tfds
<span class="token keyword">from</span> smart_tfrecord_writer <span class="token keyword">import</span> Writer
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">class</span> <span class="token class-name">NumpyWriter</span><span class="token punctuation">(</span>Writer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">extend_meta_data</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        homepage <span class="token operator">=</span> <span class="token string">&quot;&quot;</span>
        supervised_keys <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;label&quot;</span><span class="token punctuation">)</span>
        citation <span class="token operator">=</span> <span class="token string">&quot;&quot;</span>

        <span class="token keyword">return</span> description<span class="token punctuation">,</span> homepage<span class="token punctuation">,</span> supervised_keys<span class="token punctuation">,</span> citation

    <span class="token keyword">def</span> <span class="token function">features</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        features <span class="token operator">=</span> tfds<span class="token punctuation">.</span>features<span class="token punctuation">.</span>FeaturesDict<span class="token punctuation">(</span>
            <span class="token punctuation">{</span>
                <span class="token string">&quot;data&quot;</span><span class="token punctuation">:</span> tfds<span class="token punctuation">.</span>features<span class="token punctuation">.</span>Tensor<span class="token punctuation">(</span>
                    shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>
                    doc<span class="token operator">=</span><span class="token string">&quot;A random numpy array.&quot;</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token string">&quot;label&quot;</span><span class="token punctuation">:</span> tfds<span class="token punctuation">.</span>features<span class="token punctuation">.</span>ClassLabel<span class="token punctuation">(</span>
                    names<span class="token operator">=</span><span class="token punctuation">[</span>
                        <span class="token string">&quot;True&quot;</span><span class="token punctuation">,</span>
                        <span class="token string">&quot;False&quot;</span><span class="token punctuation">,</span>
                    <span class="token punctuation">]</span><span class="token punctuation">,</span>
                    doc<span class="token operator">=</span><span class="token string">&quot;A random binary label.&quot;</span><span class="token punctuation">,</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">)</span>

        <span class="token keyword">return</span> features

    <span class="token keyword">def</span> <span class="token function">process_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> example<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data<span class="token punctuation">,</span> label <span class="token operator">=</span> example
        parsed_instance <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">&quot;data&quot;</span><span class="token punctuation">:</span> data<span class="token punctuation">,</span>
            <span class="token string">&quot;label&quot;</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># ClassLabel expects a scalar</span>
        <span class="token punctuation">}</span>

        <span class="token keyword">return</span> parsed_instance


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
    <span class="token comment"># TODO: Add paths to the destination files</span>
    dest_path <span class="token operator">=</span> <span class="token string">&quot;/path/to/numpy_tfrecord&quot;</span>
    writer <span class="token operator">=</span> NumpyWriter<span class="token punctuation">(</span>
        destination_directory<span class="token operator">=</span>dest_path<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># Create random numpy arrays of shape (100, 2)</span>
    train_data <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    validation_data <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    test_data <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

    <span class="token comment"># Create random labels for the data</span>
    train_labels <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">)</span>
    validation_labels <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
    test_labels <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>

    <span class="token comment"># Structure splits information for the writer into a list of dictionaries</span>
    splits_info <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token punctuation">{</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;info&quot;</span><span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{</span>
            <span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;validation&quot;</span><span class="token punctuation">,</span>
            <span class="token string">&quot;info&quot;</span><span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>validation_data<span class="token punctuation">,</span> validation_labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{</span><span class="token string">&quot;name&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;info&quot;</span><span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

    <span class="token comment"># Write the records and have approximately 250MB per shard</span>
    writer<span class="token punctuation">.</span>write_records<span class="token punctuation">(</span>
        splits_info<span class="token operator">=</span>splits_info<span class="token punctuation">,</span>
        mb_per_shard<span class="token operator">=</span><span class="token number">250</span><span class="token punctuation">,</span>
        n_estimates_mb_per_example<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        verbose<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># Use TFDS to load in the dataset into a tf.data.Dataset object</span>
    train_ds <span class="token operator">=</span> tfds<span class="token punctuation">.</span>load<span class="token punctuation">(</span>
        <span class="token string">&quot;numpy_tfrecord&quot;</span><span class="token punctuation">,</span> data_dir<span class="token operator">=</span>dest_path<span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span> as_supervised<span class="token operator">=</span><span class="token boolean">True</span>
    <span class="token punctuation">)</span>

    <span class="token comment"># Verify the data was loaded properly</span>
    <span class="token keyword">for</span> data<span class="token punctuation">,</span> label <span class="token keyword">in</span> train_ds<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># =&gt; (100, 2)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span>  <span class="token comment"># =&gt; 0 or 1</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>And that&#39;s it! ðŸŽ‰</p><p>You can now load this dataset in with <code>tfds.load</code> and use all TensorFlow-Datasets utility functions to manipulate and use the dataset. You can also use the <code>tf.data</code> API to load in the dataset and use it with TensorFlow models!</p>`,3);function N(B,C){const i=o("Share"),e=o("ExternalLinkIcon");return c(),l("div",null,[a(i,{colorful:"",services:["email","facebook","linkedin","reddit","twitter"]}),s("div",d,[m,s("p",null,[n("If you aren't using TFRecord files to store your datasets, you should be! Avoid the headache of writing data to TFRecord files by using my "),s("a",k,[h,a(e)]),n(" package and get your conversion scripts up and running within minutes to put your data into a format that is optimized for machine learning workflows.")]),v]),s("p",null,[n("This is a shameless plug for my latest open-source project, the "),s("a",b,[n("Smart TFRecord Writer"),a(e)]),n(". This is a Python package that provides a simple and efficient way to write data to TFRecord files. The package is designed to be easy to use and to handle the complexities of writing data to TFRecord files, such as handling large datasets, handling data that does not fit into memory, and easily saving the data in a format that can be optimized by machine learning workflows. It is also built to be compatible with "),f,n("!")]),g,s("p",null,[n("However, I found that writing data to TFRecord files is a complex and time-consuming task. I personally found the documentation to be verbose and often unclear. To save others the headache, I developed the "),s("a",y,[w,a(e)]),n(" to simplify this process and to provide a tool that can be used across a wide range of projects.")]),_,s("p",null,[q,n(" uses the "),s("a",x,[n("Tensorflow-Datasets"),a(e)]),n(" (tfds) "),s("a",T,[n("features"),a(e)]),n(" module. Essentially, these are features that tfds is able to parse automatically. The goal of this function is to define the types of features present in your dataset for each example.")]),F,s("p",null,[n("There are several examples of how to use "),I,n(" in the "),s("a",W,[n("examples"),a(e)]),n(" directory of the repository. I encourage you to check them out to see how to use the package in practice. In the most basic form, the "),R,n(" function can be as simple as the following:")]),j,s("p",null,[n("To conclude, here is a complete example of how to use "),A,n(" to write a simple dataset to TFRecord files. This example uses numpy arrays in memory, but to avoid loading everything into memory, checkout this "),s("a",z,[n("ImageNet example"),a(e)]),n(".")]),D])}const L=p(u,[["render",N],["__file","smart_tfrecord_writer.html.vue"]]);export{L as default};
