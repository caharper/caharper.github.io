<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.0" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.11" />
    <style>
      html {
        background: var(--bg-color, #fff);
      }

      html[data-theme="dark"] {
        background: var(--bg-color, #1d1e1f);
      }

      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://caharper.github.io/blog/understanding_ml/endpoint_layers.html"><meta property="og:site_name" content="Clayton Harper"><meta property="og:title" content="Endpoint Layers"><meta property="og:description" content="TL;DR In this blog post, I cover the concept of endpoint layers in neural networks. These layers help you up your game in designing loss functions and more sophisticated neural ..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="article:author" content="Clayton Harper"><meta property="article:tag" content="TensorFlow"><meta property="article:tag" content="Neural Network Loss Functions"><meta property="article:published_time" content="2024-02-20T00:00:00.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Endpoint Layers","image":[""],"datePublished":"2024-02-20T00:00:00.000Z","dateModified":null,"author":[{"@type":"Person","name":"Clayton Harper","url":"https://caharper.github.io/"}]}</script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&display=swap"><title>Endpoint Layers | Clayton Harper</title><meta name="description" content="TL;DR In this blog post, I cover the concept of endpoint layers in neural networks. These layers help you up your game in designing loss functions and more sophisticated neural ...">
    <link rel="preload" href="/assets/style-ByeKlc0x.css" as="style"><link rel="stylesheet" href="/assets/style-ByeKlc0x.css">
    <link rel="modulepreload" href="/assets/app-Dw2r7XDh.js"><link rel="modulepreload" href="/assets/endpoint_layers.html-4bCBeaw1.js"><link rel="modulepreload" href="/assets/endpoint_layers.html-BH3s8lsr.js">
    <link rel="prefetch" href="/assets/index.html-BiKQbtAz.js" as="script"><link rel="prefetch" href="/assets/index.html-DRKmPfsf.js" as="script"><link rel="prefetch" href="/assets/index.html-DNi6NInB.js" as="script"><link rel="prefetch" href="/assets/index.html-DTcxWAJ8.js" as="script"><link rel="prefetch" href="/assets/cmos_spectroscopy.html-DRmua3lU.js" as="script"><link rel="prefetch" href="/assets/dct_resizing.html-B2rfgoi5.js" as="script"><link rel="prefetch" href="/assets/smart_tfrecord_writer.html-D8HgkfOh.js" as="script"><link rel="prefetch" href="/assets/spectral_convolution.html-Bqu9cpa4.js" as="script"><link rel="prefetch" href="/assets/index.html-CqAFhW5x.js" as="script"><link rel="prefetch" href="/assets/amc_deep_neural_nets.html-D_5Ys6ac.js" as="script"><link rel="prefetch" href="/assets/learnable_moments.html-DMS_412A.js" as="script"><link rel="prefetch" href="/assets/snr_boosted_amc.html-BhBUrmW1.js" as="script"><link rel="prefetch" href="/assets/synthetic_data_trackformer.html-BP56gGGs.js" as="script"><link rel="prefetch" href="/assets/index.html-Dog0wex8.js" as="script"><link rel="prefetch" href="/assets/dct_basics.html-CjnIYg37.js" as="script"><link rel="prefetch" href="/assets/index.html-BeFuYRHw.js" as="script"><link rel="prefetch" href="/assets/gradient_checkpointing.html-B10NFges.js" as="script"><link rel="prefetch" href="/assets/understanding_receptive_field.html-DLBCabFN.js" as="script"><link rel="prefetch" href="/assets/404.html-C6OQh4RT.js" as="script"><link rel="prefetch" href="/assets/index.html-CutByM1w.js" as="script"><link rel="prefetch" href="/assets/index.html-BE5FuOzL.js" as="script"><link rel="prefetch" href="/assets/index.html-ioLwqewY.js" as="script"><link rel="prefetch" href="/assets/index.html-C1IVGOen.js" as="script"><link rel="prefetch" href="/assets/cmos_spectroscopy.html-o_zhZdqv.js" as="script"><link rel="prefetch" href="/assets/dct_resizing.html-D30ABvvL.js" as="script"><link rel="prefetch" href="/assets/smart_tfrecord_writer.html-Dh1AGEA-.js" as="script"><link rel="prefetch" href="/assets/spectral_convolution.html-C1M8C_6H.js" as="script"><link rel="prefetch" href="/assets/index.html-B_1MIEPT.js" as="script"><link rel="prefetch" href="/assets/amc_deep_neural_nets.html-BGPfbiqw.js" as="script"><link rel="prefetch" href="/assets/learnable_moments.html-CBNkH9BC.js" as="script"><link rel="prefetch" href="/assets/snr_boosted_amc.html-CzP8-5dD.js" as="script"><link rel="prefetch" href="/assets/synthetic_data_trackformer.html-Dot4XxiD.js" as="script"><link rel="prefetch" href="/assets/index.html-C-1XMSZU.js" as="script"><link rel="prefetch" href="/assets/dct_basics.html-UZi_VcVc.js" as="script"><link rel="prefetch" href="/assets/index.html-BoLYbxI_.js" as="script"><link rel="prefetch" href="/assets/gradient_checkpointing.html-BPrTbJtS.js" as="script"><link rel="prefetch" href="/assets/understanding_receptive_field.html-qwbW-dAQ.js" as="script"><link rel="prefetch" href="/assets/404.html-KuYC986w.js" as="script"><link rel="prefetch" href="/assets/browser-D6eOinvE.js" as="script"><link rel="prefetch" href="/assets/auto-C0MMSKEI.js" as="script"><link rel="prefetch" href="/assets/index-uOBkQLRT.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-9nNZbZvi.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-BG2Xu2Hd.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-B2Y_eiOr.js" as="script"><link rel="prefetch" href="/assets/math.esm-BZ1CfUwa.js" as="script"><link rel="prefetch" href="/assets/search.esm-DuBqnxcF.js" as="script"><link rel="prefetch" href="/assets/notes.esm-Dp2Bpauq.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-Ctj_eavO.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-SzV8tJDW.js" as="script"><link rel="prefetch" href="/assets/SearchResult-BLsZpJNB.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><!--[--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/"><img class="vp-nav-logo" src="/assets/icon/house-solid.svg" alt><!----><span class="vp-site-name hide-in-pad">Clayton Harper</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><a aria-label="Projects" class="vp-link nav-link nav-link" href="/projects/"><span class="font-icon icon fa-fw fa-sm fas fa-laptop-code" style=""></span>Projects<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Blog" class="vp-link nav-link active nav-link active" href="/blog/"><span class="font-icon icon fa-fw fa-sm fas fa-pen-nib" style=""></span>Blog<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="Publications" class="vp-link nav-link nav-link" href="/publications/"><span class="font-icon icon fa-fw fa-sm fas fa-file-alt" style=""></span>Publications<!----></a></div><div class="nav-item hide-in-mobile"><a aria-label="About" class="vp-link nav-link nav-link" href="/about/"><span class="font-icon icon fa-fw fa-sm fas fa-user" style=""></span>About<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/caharper" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--[--><button type="button" class="search-pro-button" aria-label="Search"><svg xmlns="http://www.w3.org/2000/svg" class="icon search-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="search icon"><path d="M192 480a256 256 0 1 1 512 0 256 256 0 0 1-512 0m631.776 362.496-143.2-143.168A318.464 318.464 0 0 0 768 480c0-176.736-143.264-320-320-320S128 303.264 128 480s143.264 320 320 320a318.016 318.016 0 0 0 184.16-58.592l146.336 146.368c12.512 12.48 32.768 12.48 45.28 0 12.48-12.512 12.48-32.768 0-45.28"></path></svg><div class="search-pro-placeholder">Search</div><div class="search-pro-key-hints"><kbd class="search-pro-key">Ctrl</kbd><kbd class="search-pro-key">K</kbd></div></button><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><p class="vp-sidebar-heading clickable"><span class="font-icon icon fa-fw fa-sm fas fa-laptop-code" style=""></span><a aria-label="Projects" class="vp-link nav-link vp-sidebar-title nav-link vp-sidebar-title" href="/projects/"><!---->Projects<!----></a><!----></p><ul class="vp-sidebar-links"><li><!--[--><a aria-label="CMOS-Based Rotational Spectroscopy" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/projects/cmos_spectroscopy.html"><!---->CMOS-Based Rotational Spectroscopy<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="DCT Resizing in Neural Networks" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/projects/dct_resizing.html"><!---->DCT Resizing in Neural Networks<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="smart-tfrecord-writer" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/projects/smart_tfrecord_writer.html"><!---->smart-tfrecord-writer<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Spectral Convolution in Neural Networks" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/projects/spectral_convolution.html"><!---->Spectral Convolution in Neural Networks<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-heading clickable active"><span class="font-icon icon fa-fw fa-sm fas fa-pen-nib" style=""></span><a aria-label="Blog" class="vp-link nav-link active vp-sidebar-title nav-link active vp-sidebar-title" href="/blog/"><!---->Blog<!----></a><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable" type="button"><!----><span class="vp-sidebar-title">Frequency Analysis</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable active" type="button"><!----><span class="vp-sidebar-title">Understanding ML</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><!--[--><a aria-label="Endpoint Layers" class="vp-link nav-link active vp-sidebar-link vp-sidebar-page active nav-link active vp-sidebar-link vp-sidebar-page active" href="/blog/understanding_ml/endpoint_layers.html"><!---->Endpoint Layers<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="Introduction" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/understanding_ml/endpoint_layers.html#introduction"><!---->Introduction<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Endpoint Layer Example" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/understanding_ml/endpoint_layers.html#endpoint-layer-example"><!---->Endpoint Layer Example<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Creating the Model" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/understanding_ml/endpoint_layers.html#creating-the-model"><!---->Creating the Model<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Training the Model" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/understanding_ml/endpoint_layers.html#training-the-model"><!---->Training the Model<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="Data Pipeline" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/understanding_ml/endpoint_layers.html#data-pipeline"><!---->Data Pipeline<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Fitting the Model" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/understanding_ml/endpoint_layers.html#fitting-the-model"><!---->Fitting the Model<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Inference" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/understanding_ml/endpoint_layers.html#inference"><!---->Inference<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Takeaways" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/understanding_ml/endpoint_layers.html#takeaways"><!---->Takeaways<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Full Code Example" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/blog/understanding_ml/endpoint_layers.html#full-code-example"><!---->Full Code Example<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul><!--]--></li><li><!--[--><a aria-label="Gradient Checkpointing" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/blog/understanding_ml/gradient_checkpointing.html"><!---->Gradient Checkpointing<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Understanding Receptive Field" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/blog/understanding_ml/understanding_receptive_field.html"><!---->Understanding Receptive Field<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li></ul></section></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-heading clickable"><span class="font-icon icon fa-fw fa-sm fas fa-file-alt" style=""></span><a aria-label="Publications" class="vp-link nav-link vp-sidebar-title nav-link vp-sidebar-title" href="/publications/"><!---->Publications<!----></a><!----></p><ul class="vp-sidebar-links"><li><!--[--><a aria-label="AMC with Deep Neural Networks" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/publications/amc_deep_neural_nets.html"><!---->AMC with Deep Neural Networks<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Impacts of Synthetically Generated Data on Trackformer-based Multi-Object Tracking" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/publications/synthetic_data_trackformer.html"><!---->Impacts of Synthetically Generated Data on Trackformer-based Multi-Object Tracking<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="Learnable Statistical Moments Pooling" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/publications/learnable_moments.html"><!---->Learnable Statistical Moments Pooling<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="SNR-Boosted AMC" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/publications/snr_boosted_amc.html"><!---->SNR-Boosted AMC<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!--[--><!----><!--]--><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->Endpoint Layers</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://caharper.github.io/" target="_blank" rel="noopener noreferrer">Clayton Harper</a></span><span property="author" content="Clayton Harper"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2024-02-20T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 6 min</span><meta property="timeRequired" content="PT6M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category1" role>Blog</span><span class="page-category-item category4" role>ML Tutorials</span><!--]--><meta property="articleSection" content="Blog,ML Tutorials"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag5" role>TensorFlow</span><span class="page-tag-item tag8" role>Neural Network Loss Functions</span><!--]--><meta property="keywords" content="TensorFlow,Neural Network Loss Functions"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#introduction">Introduction</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#endpoint-layer-example">Endpoint Layer Example</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#creating-the-model">Creating the Model</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#training-the-model">Training the Model</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#data-pipeline">Data Pipeline</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#fitting-the-model">Fitting the Model</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3 toc-link level3" href="#inference">Inference</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#takeaways">Takeaways</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="#full-code-example">Full Code Example</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!--[--><!----><!--]--><div class="theme-hope-content"><div class="vp-share-buttons" style=""><!--[--><button type="button" class="vp-share-button" aria-label="email" data-balloon-pos="up"><div class="vp-share-icon colorful" style="background:#1384FF;"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024"><path d="M152 177h720c49 0 89 37 90 83L512 494 63 260c0-46 40-83 89-83M62 349v414c0 46 41 84 90 84h720c49 0 90-38 90-84V349L523 572a24 24 0 0 1-22 0z"/></svg></div></button><!----><!--]--><!--[--><button type="button" class="vp-share-button" aria-label="facebook" data-balloon-pos="up"><div class="vp-share-icon colorful" style="background:#3c599b;"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024"><path d="M295 360h93v-91c0-40 1-101 30-139 30-41 72-68 144-68 118 0 168 17 168 17l-24 138s-39-12-75-12-69 13-69 50v105h149l-10 134H562v468H388V494h-93z"/></svg></div></button><!----><!--]--><!--[--><button type="button" class="vp-share-button" aria-label="reddit" data-balloon-pos="up"><div class="vp-share-icon colorful" style="background:#ff4501;"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024"><path d="M678 779c9 9 9 18 0 27-34 37-90 55-166 55s-132-18-166-55c-9-9-9-18 0-27a17 17 0 0 1 12-6c5 0 9 2 13 6 26 29 74 43 141 43s114-14 141-43a17 17 0 0 1 13-6c5 0 9 2 12 6M400 562a82 82 0 0 1 0 112 70 70 0 0 1-53 23c-20 0-38-8-53-23a78 78 0 0 1-22-56c0-22 7-41 22-56a71 71 0 0 1 106 0m352 56c0 22-7 41-22 56a71 71 0 0 1-53 23c-21 0-38-8-53-23a78 78 0 0 1-22-56c0-22 8-40 22-56 15-16 32-23 53-23 20 0 38 7 53 23 15 15 22 34 22 56m210-106c0-29-10-54-29-74a94 94 0 0 0-71-31c-28 0-52 10-72 31-73-53-160-81-260-85l52-250 168 40c0 21 7 40 21 55 15 16 32 23 53 23s38-7 53-23 22-34 22-56-7-41-22-57a71 71 0 0 0-53-23c-30 0-52 15-67 44L572 63c-10-3-17 2-21 14l-57 276c-101 5-187 33-259 86a94 94 0 0 0-73-32c-28 0-51 10-71 31a105 105 0 0 0-29 74 108 108 0 0 0 57 96 241 241 0 0 0-5 49c0 84 39 156 117 216 78 59 172 89 282 89s205-30 283-89c78-60 117-132 117-216 0-19-2-35-6-50a108 108 0 0 0 55-95"/></svg></div></button><!----><!--]--><!--[--><button type="button" class="vp-share-button" aria-label="twitter" data-balloon-pos="up"><div class="vp-share-icon colorful" style="background:#000;"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024"><path d="m587 451 291-339h-69L555 407 354 112H120l305 446-305 354h68l268-310 213 310h235zM214 163h107l488 699H702z"/></svg></div></button><!----><!--]--></div><div class="hint-container info"><p class="hint-container-title">TL;DR</p><p>In this blog post, I cover the concept of endpoint layers in neural networks. These layers help you up your game in designing loss functions and more sophisticated neural network architectures. Enpoint layers allow you to design arbitary losses and metrics that don&#39;t fit the <code>loss(y_true, y_pred)</code> signature.</p><p>I provide reproducible code examples to help you understand the concept.</p></div><h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true">#</a> Introduction</h2><p>Endpoint layers are a powerful concept in neural network design. They allow you to design arbitrary losses and metrics that don&#39;t fit the <code>loss(y_true, y_pred)</code> signature. When designing a network that has multiple loss functions, loss weights, or you want to add a loss that is dependent on intermediate network activations, enpoint layers are your best friend. And they&#39;re easy to code! 😄</p><p>Simple loss functions like mean squared error and cross entropy take the form <code>loss(y_true, y_pred)</code>. Your input pipeline passes a label and sample to the network, and the network outputs a prediction. The loss function then compares the prediction to the label and returns a scalar value. This is a simple and effective way to train a network. However, when you start to implement more nuanced loss functions, you may find that the <code>loss(y_true, y_pred)</code> signature is too restrictive. Another case is when you have multiple loss functions that contribute to your overall loss, but you may want to individually track the performance of each loss rather than the combined sum. These are cases where endpoint layers come in play.</p><p>In this tutorial, I will cover a Keras implementation of endpoint layers. François Chollet has a great <a href="https://keras.io/examples/keras_recipes/endpoint_layer_pattern/" target="_blank" rel="noopener noreferrer">code example<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>, but I will provide a more detailed explanation in this post for those who are new to the concept.</p><h2 id="endpoint-layer-example" tabindex="-1"><a class="header-anchor" href="#endpoint-layer-example" aria-hidden="true">#</a> Endpoint Layer Example</h2><p>This may be a bit of a contrived example, but it should be illustrative. Say you want to train a classifier for the MNIST dataset, but you also want to add a loss that is dependent on the network&#39;s activations. Specifically, say you want the variance of the activations from the one layer to match the variance of the activations from another layer. Here, we&#39;ll use the activations following the first layer and the penultimate layer (just before the output layer).</p><p>To start, let&#39;s create our endpoint layer. To make it an <u><strong>end</strong></u>point layer, the point is to make it the last layer in the network containing all losses (maybe excluding regularization losses internal to other layers). With that in mind, if we also want to include a loss function that follows the traditional <code>loss(y_true, y_pred)</code> signature, we need to pass the labels to this layer as well. This can be a bit strange at first, but this adds a ton of flexibility to the model design. Once the model is trained, we can simply not pass the labels to the endpoint layer so it is ready for inference.</p><p>In total, our endpoint layer for this example will need the model output logits, the labels, and the activations from the first and penultimate layers. Let&#39;s make the endpoint layer now and worry about the changes to the data pipeline in a later section.</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf


<span class="token keyword">class</span> <span class="token class-name">ClassificationAndVarianceMatchingLoss</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cross_entropy_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> variance_loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cross_entropy_weight <span class="token operator">=</span> cross_entropy_weight
        self<span class="token punctuation">.</span>variance_loss_weight <span class="token operator">=</span> variance_loss_weight

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> targets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> act_1<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> act_2<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># If one of targets, act_1, or act_2 are not None, all should be not None</span>
        none_training_params <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token boolean">True</span> <span class="token keyword">if</span> param <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">else</span> <span class="token boolean">False</span> <span class="token keyword">for</span> param <span class="token keyword">in</span> <span class="token punctuation">[</span>targets<span class="token punctuation">,</span> act_1<span class="token punctuation">,</span> act_2<span class="token punctuation">]</span>
        <span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token builtin">any</span><span class="token punctuation">(</span>none_training_params<span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token keyword">not</span> <span class="token builtin">all</span><span class="token punctuation">(</span>none_training_params<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                <span class="token string">&quot;If one of targets, act_1, or act_2 are not None, all should be not None&quot;</span>
            <span class="token punctuation">)</span>

        <span class="token comment"># Compute traditional cross entropy loss</span>
        <span class="token keyword">if</span> targets <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            cross_entropy_loss <span class="token operator">=</span> <span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>
                    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>sparse_categorical_crossentropy<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token operator">*</span> self<span class="token punctuation">.</span>cross_entropy_weight
            <span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_loss<span class="token punctuation">(</span>cross_entropy_loss<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_metric<span class="token punctuation">(</span>
                cross_entropy_loss<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;cross_entropy_loss&quot;</span><span class="token punctuation">,</span> aggregation<span class="token operator">=</span><span class="token string">&quot;mean&quot;</span>
            <span class="token punctuation">)</span>

            <span class="token comment"># Add the accuracy metric</span>
            self<span class="token punctuation">.</span>add_metric<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>
                    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>sparse_categorical_accuracy<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span>
                name<span class="token operator">=</span><span class="token string">&quot;accuracy&quot;</span><span class="token punctuation">,</span>
                aggregation<span class="token operator">=</span><span class="token string">&quot;mean&quot;</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>

        <span class="token comment"># Compute the variance loss</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">all</span><span class="token punctuation">(</span>none_training_params<span class="token punctuation">)</span><span class="token punctuation">:</span>
            variance_loss <span class="token operator">=</span> <span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>
                    tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span>square<span class="token punctuation">(</span>
                        tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span>reduce_variance<span class="token punctuation">(</span>act_1<span class="token punctuation">)</span> <span class="token operator">-</span> tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span>reduce_variance<span class="token punctuation">(</span>act_2<span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token operator">*</span> self<span class="token punctuation">.</span>variance_loss_weight
            <span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_loss<span class="token punctuation">(</span>variance_loss<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_metric<span class="token punctuation">(</span>variance_loss<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;variance_loss&quot;</span><span class="token punctuation">,</span> aggregation<span class="token operator">=</span><span class="token string">&quot;mean&quot;</span><span class="token punctuation">)</span>

        <span class="token comment"># Return the prediction provided the output logits</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>

    <span class="token comment"># Make the layer serializable</span>
    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        config <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        config<span class="token punctuation">.</span>update<span class="token punctuation">(</span>
            <span class="token punctuation">{</span>
                <span class="token string">&quot;cross_entropy_weight&quot;</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>cross_entropy_weight<span class="token punctuation">,</span>
                <span class="token string">&quot;variance_loss_weight&quot;</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>variance_loss_weight<span class="token punctuation">,</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> config
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>To compute the variance loss, we use mean-squared error between the variance of the activations from the first layer and the penultimate layer to ensure they&#39;re close to one another in magnitude. We also compute the traditional cross entropy loss for classification. We add both of these losses to the layer using <code>self.add_loss</code>. We also add the losses to the layer&#39;s metrics using <code>self.add_metric</code>. This might be really helpful for tuning the <code>cross_entropy_weight</code> and <code>variance_loss_weight</code> hyperparameters. You may want one to be slightly more important than the other, or you may want to balance their importance. By changing the weights, you can see how the losses change and how the model&#39;s performance changes.</p><div class="hint-container note"><p class="hint-container-title">Note</p><p>During infernce, all we will need to pass to the endpoint layer is the model output logits, just like a traditional model. The other inputs are only needed during training. That is why these are all optional parameters in the <code>call</code> method.</p></div><h2 id="creating-the-model" tabindex="-1"><a class="header-anchor" href="#creating-the-model" aria-hidden="true">#</a> Creating the Model</h2><p>Next, let&#39;s design a simple convolutional neural network (CNN) for the MNIST dataset with our endpoint layer. Remember, we need to pass the inputs to the endpoint layer during training, so we need to make an <code>Input</code> layer that will pass the ground truth labels to the endpoint layer. Here&#39;s how we can do that:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">make_model</span><span class="token punctuation">(</span>training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;image&quot;</span><span class="token punctuation">)</span>
    model_inputs <span class="token operator">=</span> <span class="token punctuation">[</span>inputs<span class="token punctuation">]</span>

    x1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    x2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
    x3 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
    net <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>GlobalAveragePooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x3<span class="token punctuation">)</span>
    output_logits <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;output_logit&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>

    <span class="token comment"># Create the endpoint layer</span>
    <span class="token keyword">if</span> training<span class="token punctuation">:</span>
        targets <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;label&quot;</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
        model_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>targets<span class="token punctuation">)</span>
        endpoint_layer <span class="token operator">=</span> ClassificationAndVarianceMatchingLoss<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">&quot;endpoint&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>
            output_logits<span class="token punctuation">,</span> targets<span class="token punctuation">,</span> x1<span class="token punctuation">,</span> x3
        <span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        endpoint_layer <span class="token operator">=</span> ClassificationAndVarianceMatchingLoss<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">&quot;endpoint&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>
            output_logits
        <span class="token punctuation">)</span>

    <span class="token comment"># Create the model</span>
    model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span>model_inputs<span class="token punctuation">,</span> outputs<span class="token operator">=</span>endpoint_layer<span class="token punctuation">)</span>

    <span class="token keyword">return</span> model
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">Tip</p><p>Naming the input layers (and output layers) if you have multiple makes life much easier when designing your input pipeline. It&#39;s good practice to name all of your layers, but these are particularly important.</p></div><h2 id="training-the-model" tabindex="-1"><a class="header-anchor" href="#training-the-model" aria-hidden="true">#</a> Training the Model</h2><h3 id="data-pipeline" tabindex="-1"><a class="header-anchor" href="#data-pipeline" aria-hidden="true">#</a> Data Pipeline</h3><p>First, we need to load in the MNIST dataset. We can use the <code>tensorflow_datasets</code> <a href="https://www.tensorflow.org/datasets" target="_blank" rel="noopener noreferrer">package<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> to do this. Then, we can implement our data pipeline using the <code>tf.data</code> <a href="https://www.tensorflow.org/guide/data" target="_blank" rel="noopener noreferrer">API<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>. Here&#39;s how we can do that:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">prepare_ds</span><span class="token punctuation">(</span>ds<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> shuffle<span class="token punctuation">:</span>
        ds <span class="token operator">=</span> ds<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>batch_size <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span>

    ds <span class="token operator">=</span> ds<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>
        <span class="token keyword">lambda</span> x<span class="token punctuation">,</span> y<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">&quot;image&quot;</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> <span class="token string">&quot;label&quot;</span><span class="token punctuation">:</span> y<span class="token punctuation">}</span>
    <span class="token punctuation">)</span>

    ds <span class="token operator">=</span> ds<span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>AUTOTUNE<span class="token punctuation">)</span>
    <span class="token keyword">return</span> ds


<span class="token comment"># Load in the MNIST dataset</span>
train_ds<span class="token punctuation">,</span> test_ds <span class="token operator">=</span> tfds<span class="token punctuation">.</span>load<span class="token punctuation">(</span>
    <span class="token string">&quot;mnist&quot;</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shuffle_files<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> as_supervised<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token comment"># Prepare the datasets</span>
batch_size <span class="token operator">=</span> <span class="token number">32</span>
train_ds <span class="token operator">=</span> prepare_ds<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_ds <span class="token operator">=</span> prepare_ds<span class="token punctuation">(</span>test_ds<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Our pipeline is ready! Note that the <code>prepare_ds</code> function structures the dataset to have a dictionary with keys <code>&quot;image&quot;</code> and <code>&quot;label&quot;</code>, matching up with our names from the input layers to the model. This is where naming layers makes your life easier. Keras will know how to match up the inputs to the model appropriately.</p><h3 id="fitting-the-model" tabindex="-1"><a class="header-anchor" href="#fitting-the-model" aria-hidden="true">#</a> Fitting the Model</h3><p>Now, we can fit the model:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># Create the model</span>
model <span class="token operator">=</span> make_model<span class="token punctuation">(</span>training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Compile and train the model</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">&#39;adam&#39;</span><span class="token punctuation">)</span>
history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># Evaluate the model</span>
eval_results <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_ds<span class="token punctuation">,</span> return_dict<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>eval_results<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Feel free to increase the epochs, but I&#39;m just showing a quick example here. Training for one epoch on my machine, these are the printed results of <code>eval_results</code>:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token punctuation">{</span>
    <span class="token string">&quot;loss&quot;</span><span class="token punctuation">:</span> <span class="token number">2.3025918006896973</span><span class="token punctuation">,</span>
    <span class="token string">&quot;cross_entropy_loss&quot;</span><span class="token punctuation">:</span> <span class="token number">2.30259108543396</span><span class="token punctuation">,</span>
    <span class="token string">&quot;accuracy&quot;</span><span class="token punctuation">:</span> <span class="token number">0.12699680030345917</span><span class="token punctuation">,</span>
    <span class="token string">&quot;variance_loss&quot;</span><span class="token punctuation">:</span> <span class="token number">2.23870438276208e-06</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Not a state-of-the-art model 😂. But, we can see that the model was able to utilize the endpoint layer to compute the variance loss and the cross entropy loss.</p><p>This is a simple example, but it should illustrate the power of endpoint layers. You are really only limited by your imagination when it comes to designing loss functions with this approach.</p><h3 id="inference" tabindex="-1"><a class="header-anchor" href="#inference" aria-hidden="true">#</a> Inference</h3><p>During inference, you can simply set the <code>training</code> parameter to <code>False</code>. This just sets the <code>targets</code>, <code>act_1</code>, and <code>act_2</code> parameters to <code>None</code> in the endpoint layer. Here&#39;s how you can do that:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># Create the inference model</span>
inference_model <span class="token operator">=</span> make_model<span class="token punctuation">(</span>training<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># Load in the weights from the training model</span>
inference_model<span class="token punctuation">.</span>set_weights<span class="token punctuation">(</span>model<span class="token punctuation">.</span>get_weights<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Create a random batch of data</span>
random_batch <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Predict the random batch of data</span>
predictions <span class="token operator">=</span> inference_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>random_batch<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="takeaways" tabindex="-1"><a class="header-anchor" href="#takeaways" aria-hidden="true">#</a> Takeaways</h2><p>Endpoint layers are extremely flexible, allowing you to design some crazy cool loss functions. By incorporating them into your repertoire, you can design more sophisticated neural network architectures and keep your code super clean. I hope this tutorial has helped you understand the concept of endpoint layers, and if you have any questions, feel free to reach out!</p><h2 id="full-code-example" tabindex="-1"><a class="header-anchor" href="#full-code-example" aria-hidden="true">#</a> Full Code Example</h2><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> tensorflow_datasets <span class="token keyword">as</span> tfds


<span class="token keyword">class</span> <span class="token class-name">ClassificationAndVarianceMatchingLoss</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cross_entropy_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> variance_loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cross_entropy_weight <span class="token operator">=</span> cross_entropy_weight
        self<span class="token punctuation">.</span>variance_loss_weight <span class="token operator">=</span> variance_loss_weight

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> targets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> act_1<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> act_2<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># If one of targets, act_1, or act_2 are not None, all should be not None</span>
        none_training_params <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token boolean">True</span> <span class="token keyword">if</span> param <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">else</span> <span class="token boolean">False</span> <span class="token keyword">for</span> param <span class="token keyword">in</span> <span class="token punctuation">[</span>targets<span class="token punctuation">,</span> act_1<span class="token punctuation">,</span> act_2<span class="token punctuation">]</span>
        <span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token builtin">any</span><span class="token punctuation">(</span>none_training_params<span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token keyword">not</span> <span class="token builtin">all</span><span class="token punctuation">(</span>none_training_params<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span>
                <span class="token string">&quot;If one of targets, act_1, or act_2 are not None, all should be not None&quot;</span>
            <span class="token punctuation">)</span>

        <span class="token comment"># Compute traditional cross entropy loss</span>
        <span class="token keyword">if</span> targets <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            cross_entropy_loss <span class="token operator">=</span> <span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>
                    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>sparse_categorical_crossentropy<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token operator">*</span> self<span class="token punctuation">.</span>cross_entropy_weight
            <span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_loss<span class="token punctuation">(</span>cross_entropy_loss<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_metric<span class="token punctuation">(</span>
                cross_entropy_loss<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;cross_entropy_loss&quot;</span><span class="token punctuation">,</span> aggregation<span class="token operator">=</span><span class="token string">&quot;mean&quot;</span>
            <span class="token punctuation">)</span>

            <span class="token comment"># Add the accuracy metric</span>
            self<span class="token punctuation">.</span>add_metric<span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>
                    tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>sparse_categorical_accuracy<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>
                <span class="token punctuation">)</span><span class="token punctuation">,</span>
                name<span class="token operator">=</span><span class="token string">&quot;accuracy&quot;</span><span class="token punctuation">,</span>
                aggregation<span class="token operator">=</span><span class="token string">&quot;mean&quot;</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>

        <span class="token comment"># Compute the variance loss</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">all</span><span class="token punctuation">(</span>none_training_params<span class="token punctuation">)</span><span class="token punctuation">:</span>
            variance_loss <span class="token operator">=</span> <span class="token punctuation">(</span>
                tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>
                    tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span>square<span class="token punctuation">(</span>
                        tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span>reduce_variance<span class="token punctuation">(</span>act_1<span class="token punctuation">)</span> <span class="token operator">-</span> tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span>reduce_variance<span class="token punctuation">(</span>act_2<span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                <span class="token operator">*</span> self<span class="token punctuation">.</span>variance_loss_weight
            <span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_loss<span class="token punctuation">(</span>variance_loss<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_metric<span class="token punctuation">(</span>variance_loss<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;variance_loss&quot;</span><span class="token punctuation">,</span> aggregation<span class="token operator">=</span><span class="token string">&quot;mean&quot;</span><span class="token punctuation">)</span>

        <span class="token comment"># Return the prediction provided the output logits</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>

    <span class="token comment"># Make the layer serializable</span>
    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        config <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        config<span class="token punctuation">.</span>update<span class="token punctuation">(</span>
            <span class="token punctuation">{</span>
                <span class="token string">&quot;cross_entropy_weight&quot;</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>cross_entropy_weight<span class="token punctuation">,</span>
                <span class="token string">&quot;variance_loss_weight&quot;</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>variance_loss_weight<span class="token punctuation">,</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> config


<span class="token keyword">def</span> <span class="token function">make_model</span><span class="token punctuation">(</span>training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;image&quot;</span><span class="token punctuation">)</span>
    model_inputs <span class="token operator">=</span> <span class="token punctuation">[</span>inputs<span class="token punctuation">]</span>

    x1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    x2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
    x3 <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">&quot;relu&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x2<span class="token punctuation">)</span>
    net <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>GlobalAveragePooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x3<span class="token punctuation">)</span>
    output_logits <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;output_logit&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>net<span class="token punctuation">)</span>

    <span class="token comment"># Create the endpoint layer</span>
    <span class="token keyword">if</span> training<span class="token punctuation">:</span>
        targets <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">&quot;label&quot;</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
        model_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>targets<span class="token punctuation">)</span>
        endpoint_layer <span class="token operator">=</span> ClassificationAndVarianceMatchingLoss<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">&quot;endpoint&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>
            output_logits<span class="token punctuation">,</span> targets<span class="token punctuation">,</span> x1<span class="token punctuation">,</span> x3
        <span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        endpoint_layer <span class="token operator">=</span> ClassificationAndVarianceMatchingLoss<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">&quot;endpoint&quot;</span><span class="token punctuation">)</span><span class="token punctuation">(</span>
            output_logits
        <span class="token punctuation">)</span>

    <span class="token comment"># Create the model</span>
    model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span>model_inputs<span class="token punctuation">,</span> outputs<span class="token operator">=</span>endpoint_layer<span class="token punctuation">)</span>

    <span class="token keyword">return</span> model


<span class="token keyword">def</span> <span class="token function">prepare_ds</span><span class="token punctuation">(</span>ds<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> shuffle<span class="token punctuation">:</span>
        ds <span class="token operator">=</span> ds<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>batch_size <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span>

    ds <span class="token operator">=</span> ds<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>
        <span class="token keyword">lambda</span> x<span class="token punctuation">,</span> y<span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">&quot;image&quot;</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>x<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> <span class="token string">&quot;label&quot;</span><span class="token punctuation">:</span> y<span class="token punctuation">}</span>
    <span class="token punctuation">)</span>

    ds <span class="token operator">=</span> ds<span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>AUTOTUNE<span class="token punctuation">)</span>
    <span class="token keyword">return</span> ds


<span class="token comment"># Load in the MNIST dataset</span>
train_ds<span class="token punctuation">,</span> test_ds <span class="token operator">=</span> tfds<span class="token punctuation">.</span>load<span class="token punctuation">(</span>
    <span class="token string">&quot;mnist&quot;</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shuffle_files<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> as_supervised<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>

<span class="token comment"># Prepare the datasets</span>
batch_size <span class="token operator">=</span> <span class="token number">32</span>
train_ds <span class="token operator">=</span> prepare_ds<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_ds <span class="token operator">=</span> prepare_ds<span class="token punctuation">(</span>test_ds<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span>

<span class="token comment"># Create the model</span>
model <span class="token operator">=</span> make_model<span class="token punctuation">(</span>training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Compile and train the model</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">&quot;adam&quot;</span><span class="token punctuation">)</span>
history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># Evaluate the model</span>
eval_results <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_ds<span class="token punctuation">,</span> return_dict<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># Create the inference model</span>
inference_model <span class="token operator">=</span> make_model<span class="token punctuation">(</span>training<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># Load in the weights from the training model</span>
inference_model<span class="token punctuation">.</span>set_weights<span class="token punctuation">(</span>model<span class="token punctuation">.</span>get_weights<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Create a random batch of data</span>
random_batch <span class="token operator">=</span> tf<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Predict the random batch of data</span>
predictions <span class="token operator">=</span> inference_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>random_batch<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></div><!--[--><!----><!--]--><footer class="page-meta"><!----><div class="meta-item git-info"><!----><!----></div></footer><nav class="vp-page-nav"><!----><a aria-label="Gradient Checkpointing" class="vp-link nav-link next nav-link next" href="/blog/understanding_ml/gradient_checkpointing.html"><div class="hint">Next<span class="arrow end"></span></div><div class="link">Gradient Checkpointing<!----></div></a></nav><!----><!--[--><!----><!--]--><!--]--></main><!--]--><footer class="vp-footer-wrapper"><!----><div class="vp-copyright">Copyright © 2024 Clayton Harper </div></footer></div><!--]--><!--]--><!----><!----><!--]--></div>
    <script type="module" src="/assets/app-Dw2r7XDh.js" defer></script>
  </body>
</html>
